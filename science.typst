#import "@preview/numbly:0.1.0": numbly

#set text(
  size: 12pt,
  font: (
    // (name: "Times New Roman", covers: "latin-in-cjk"),
    "Source Han Sans HC",
  )
)

#show link: set text(blue)

#show raw: set text(1em*(5/4))
#show raw.where(block:false): it => highlight(fill: luma(200), extent: 2pt)[#it]
#show raw.where(block:true): it => block(
  fill: luma(230),
  inset: 8pt,
  radius: 5pt,
  it
)

#set heading(
  numbering: numbly(
    "{1}、",
    "{1}.{2} ",
    "{1}.{2}.{3} ",
    "{1}.{2}.{3}.{4} ",
  ),
)
#show heading: set block(below: 1.1em)

#let title(body) = [
  #set text(size: 2.5em, weight: "bold")
  #set align(center)
  #rect(fill: luma(230), inset: 8pt, radius: 6pt)[
    #body
  ]
]


#grid(
  columns: (1fr),
  rows: (5em, 1em),
  title[影像表格文字化的實作與學習],
  align(center)[作者：薛詠謙]
)
= 動機
在尋找合適校系的過程中，我發現 #link("https://university-tw.ldkrsi.men/")[University
 TW] 所提供的分數搜尋功能非常實用。
不過，該網站的資料更新速度並不一定與官方同步，而 *大學甄選入學委員會* 所公布的錄取分數資料又多以 *圖片表格* 的形式呈現，難以直接整理或分析。

因此，我產生了想要將影像表格轉換成可數位化利用文字資料的想法，因此，我開始學習 *OCR*（光學文字辨識）技術，並嘗試實現影像中文字資料的自動化擷取與轉換。

= 資料蒐集

根據 @table-ocr-dissertion 與 @table-ocr-medium ，影像表格分析流程可簡略分為以下幾個步驟：

+ *影像前處理*：對原始影像進行去噪、二值化或對比度等調整。
+ *表格分割*：偵測並標註表格的行列結構，將整體表格拆分為單元格。
+ *文字辨識*：對每個單元格進行 OCR 辨識，取得對應文字內容。
+ *轉換輸出格式*：將最終文字結果整理成結構化資料，如 `csv` 或 `json` 。

== 影像預處理

=== 二值化

`threshold(thresh: f64)` 函式可將灰階影像轉換為純黑與純白的二值化影像。
然而，由於中文字筆劃粗細不一，閾值 ( `thresh` ) 的設定若不恰當，可能會降低文字辨識的準確度。

#grid(
  stroke: black,
  columns: (1fr,1fr, 1fr),
  fill: luma(200),
  align: horizon,
  row-gutter: .5em,
  inset: .5em,
)[
  #figure(
    image("thersh-100.png"),
    gap: .8em,
    supplement: "圖",
    caption: [閾值=100]
  ) <thresh-100>
][
  #figure(
    image("thersh-150.png"),
    gap: .8em,
    supplement: "圖",
    caption: [閾值=150]
  ) <thresh-150>
][
  #figure(
    image("thersh-200.png"),
    gap: .8em,
    supplement: "圖",
    caption: [閾值=200]
  ) <thresh-200>
]

因此，雖然在此範例中使用 @thresh-150（閾值 = 150）的二值化處理結果尚可接受，
但鑒於本專案涉及多種不同文字樣式，最終我決定在文字辨識的預處理階段不採用二值化。

== 文字辨識

=== #link("https://github.com/tesseract-ocr/tesseract")[`Tesseract`]

#grid(
  columns: (5fr, 4fr),
  align: horizon,
  column-gutter: 0.5em,
  inset: .2em,
  row-gutter: 0em,
  text[將中文文字影像直接輸入 `tesseract` 進行辨識時，即使經過灰階化等前處理，辨識效果仍不盡理想。推測原因可能在於大考中心提供的檔案 *解析度* 過低#super[@dpi-proof]，導致模型無法正確辨識文字。],
  grid(
    gutter: 8pt,
    image("figure-1.png"),
    scale(75%, reflow: true)[`tesseract figure-1.png - -l chi_tra` \ *無法* 辨識出文字]
  ),
  text[不過，`tesseract` 在數字的辨識上表現十分精準，能穩定且無誤地擷取出校系代碼欄位的資料。],
  grid(
    gutter: 8pt,
    align(center)[#image("figure-2.png")],
    scale(75%, reflow: true)[`tesseract figure-2.png - -c tessedit_char_whitelist=0123456789` \ 成功辨識出 #highlight[011012]]
  ),
)

=== #link("https://github.com/PaddlePaddle/PaddleOCR")[PaddleOCR]

PaddleOCR 是由百度開發的文字辨識工具，相較於 `tesseract` ，在中文文字的擷取上具有顯著的提升。

在大多數情況下，PaddleOCR 能夠成功辨識中文文字，其特色包括：

- 少數情況下可能漏字，例如在 @failed-attempt 中僅辨識出「#highlight(fill: luma(200))[(華語文教學組)]」。
- 純數字辨識有時也會漏字，如在 @pure-numbers 中僅辨識出「#highlight(fill: luma(200))[1012]」。
- 對中英文混合及標點符號具有良好容錯性，大部分情況下都能正確辨識，例如在 @mixed-language 成功辨識出「#highlight(fill: luma(200))[(英文+數學A)25]」。

#grid(
  stroke: black,
  columns: (1fr,1fr, 1fr),
  fill: luma(200),
  align: horizon,
  row-gutter: .5em,
  inset: .5em,
)[
  #figure(
    image("failed-ocr.png"),
    supplement: "圖",
    gap: .8em,
    caption: []
  ) <failed-attempt>
][
  #figure(
    image("figure-2.png", height: 3%),
    supplement: "圖",
    gap: .8em,
    caption: []
  ) <pure-numbers>
][
  #figure(
    image("mixed-language.png"),
    supplement: "圖",
    gap: .8em,
    caption: []
  ) <mixed-language>
]

=== 小結
綜上所述，將 `tesseract` 用於單元格的純數字辨識，而將 PaddleOCR 作為主要文字辨識工具，似乎為最佳組合。

= 操作方法
#grid(
  columns: (5fr,4fr),
  align: horizon,
  column-gutter: 2em
)[
根據 @standards 所示，大考中心提供的篩選標準圖表可能包含多個區塊。
因此，需要先辨識各區域的 *外圍邊線* 並進行分割，再辨識表格內的 *分割線* ，將表格切分成單元格，最後進行 *文字辨識*，並將結果整理成結構化的 JSON 格式。
][
  #figure(
    image("standards.png"),
    supplement: "圖",
    gap: .8em,
    caption: []
  ) <standards>
]

處理流程可簡述如下：

外圍邊線辨識 → 區域分割 → 表格邊線辨識 → 單元格分割 → 文字辨識 → 將資料結構化

== 外圍邊線辨識與分割

根據 @table-ocr-dissertion，可使用 `find_contours_with_hierarchy` 函數進行直線邊緣偵測。
然而，此方法同時會偵測到文字筆劃中的直線，導致難以準確判定外框邊界。

為消除文字干擾，可採用*膨脹與腐蝕（morphological closing）*處理。
#figure(
```rust
let kernel =
    get_structuring_element(imgproc::MORPH_RECT, Size::new(20, 5), Point::new(-1, -1))?;

let mut closed = Mat::default();

morphology_ex(
    &thresh,
    &mut closed,
    imgproc::MORPH_CLOSE,
    &kernel,
    Point::new(-1, -1),
    1,
    BORDER_CONSTANT,
    Scalar::default(),
)?;
```,
caption: [其中 `thresh` 為經過二值化的影像],
supplement: "表"
) <morphology>

由 @morphology 和轉換過後的 @morphed-standards 可見，以長 20、寬 5 的矩形結構元素（kernel）進行運算，能有效的腐蝕掉文字，不過同時也腐蝕掉了表格。
為保留表格結構，可將處理後的影像與原始影像進行 `bitwise_or` 運算，以刪除文字、復原表格，如 @morphed-ored-standards 所見。

#grid(
  stroke: ( thickness: 2pt, paint: black ),
  inset: 1em,
  columns: (1fr,1fr),
  align: horizon,
)[
#figure(
  image("standards-morphologied.png", height: 30%),
  supplement: "圖",
  caption: [經過腐蝕過後的圖像]
) <morphed-standards>
][
#figure(
  image("standards-morphologied-and-ored.png", height: 30%),
  supplement: "圖",
  caption: [經 bitwise_or 合併的圖像]
) <morphed-ored-standards>
]


== 表格邊線辨識

== 單元格分割

== 資料結構化

#bibliography("works.yaml", title: "參考文獻")
